{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Jaccard score for 5/20 news groups "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project scope\n",
    "\n",
    "## Requiremets for result\n",
    "### Build a comparison table and analyse: \n",
    "1. The most efficient number of words per class profile (20, 50, 100)\n",
    "2. The best classifier\n",
    "3. The best combiation of both\n",
    "\n",
    "## [Imports](#imports)\n",
    " **Import necessary libs and objects from skleran**\n",
    " \n",
    "### Dataset\n",
    "- fetch_20newsgroups (select 5 from 20)\n",
    "\n",
    "### Metrics\n",
    "- confusion_matrix\n",
    "- classification_report\n",
    "- accuracy_score\n",
    "- jaccard_similarity_score\n",
    "\n",
    "### Classifier\n",
    "- SGDClassifier\n",
    "- LogisticRegression\n",
    "- KNeighborsClassifier\n",
    "\n",
    "### Vectorizer\n",
    "- CountVectorizer\n",
    "- TfidfTransformer\n",
    "\n",
    "## General algorithm \n",
    "\n",
    "### [Prepare row sets](#prep)\n",
    "1. Unpack grops of selected categories separetely\n",
    "2. Remove: headers, footers, quotes\n",
    "3. Split to train and test sets\n",
    "\n",
    "### [Vectorize sets](#vect)\n",
    "**for each set**\n",
    "- remove stop words\n",
    "- calculate count score (fit, transform)\n",
    "- calculate TF-IDF score (fit, transform)\n",
    "\n",
    "### [Build Jaccard profiles](#bjp)\n",
    "After basic vectorizstion and cleaning data calculate jaccard score for each word. \n",
    "Based on requirements build a profiles for each class\n",
    "\n",
    "### [Train classifier](#train)\n",
    "1. Combine all profiles to single vector\n",
    "2. Train classifier on each calculated class profile (5 classe by 3 profile: 20, 50, 100 words)\n",
    "\n",
    "### [Test prediction](#pred)\n",
    "Run a predict method to predict values using trained classifier\n",
    "\n",
    "### [Calculate accuracy](#report)\n",
    "Using imported metrics calculate accurasy of each cobmination of classifier-class profile\n",
    "Calsulated info store in a disct:\n",
    "\n",
    "```\n",
    "{\n",
    "    'class_crofile_name' : {\n",
    "        'valume_of_profile': number_of_words,\n",
    "        'accuracy': accuracy_of_prediction,\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs and dataset<a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, jaccard_similarity_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import 20 news groups dataset and select 5 gorups <a id=\"prep\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "categories = ['sci.space', 'comp.graphics', 'talk.politics.misc', 'rec.sport.hockey', 'comp.sys.mac.hardware'] \n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "# twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories = categories, remove = remove )\n",
    "# twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories = categories, remove = remove )\n",
    "\n",
    "for category in categories:\n",
    "    train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories = [category], remove = remove )\n",
    "    test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories = [category], remove = remove )\n",
    "    datasets.append((train, test))\n",
    "print(len(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization <a id=\"vect\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectores = []\n",
    "for train, test in datasets:\n",
    "    vect = CountVectorizer(max_features=100,stop_words = 'english')\n",
    "    vect.fit(train.data)\n",
    "    train_data = vect.transform(train.data)\n",
    "    test_data = vect.transform(test.data)\n",
    "    vectores.append((train_data, test_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectores = []\n",
    "for target, data in enumerate(vectores):\n",
    "    tfidf = TfidfTransformer(use_idf = True).fit(data[0])\n",
    "    train_data_tfidf = tfidf.transform(data[0])\n",
    "    tfidf_vectores.append((train_data_tfidf, str(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[('simms', 63.638236720259407), ('info', 40.217516084378431), ('got', 34.489623755977327), ('meg', 28.974849998822815), ('think', 28.337530277047314), ('computer', 27.555136319539837), ('hard', 25.862687158568772), ('time', 24.214750077698607), ('nubus', 23.623757516146643), ('need', 22.128767174173799)]\n",
      "100\n",
      "1\n",
      "[('hard', 37.584925681349404), ('support', 32.852919317138479), ('machine', 30.786586539794023), ('cpu', 28.24911095519138), ('info', 25.856203116615056), ('macs', 25.612822548625736), ('time', 24.688387491054481), ('drive', 24.669020709429397), ('drives', 24.240591856766716), ('plus', 23.668381802928767)]\n",
      "100\n",
      "2\n",
      "[('modem', 42.89142619285699), ('cd', 28.872638336374333), ('disk', 27.732359486938975), ('external', 26.007861078641259), ('support', 23.939126792300943), ('good', 23.59494928308845), ('hardware', 20.737195960640889), ('cache', 20.348902965458109), ('mb', 19.729841803797793), ('just', 19.50207281270664)]\n",
      "100\n",
      "3\n",
      "[('mb', 52.349835237372403), ('used', 48.657122613379769), ('nubus', 45.692029623961879), ('macs', 36.287294395516483), ('power', 36.096157784330536), ('order', 35.4187448151159), ('ve', 34.432549648563388), ('think', 33.090444204642743), ('right', 32.397574549549716), ('works', 32.122383920875542)]\n",
      "100\n",
      "4\n",
      "[('mac', 37.551050497433955), ('apple', 33.95314301710345), ('drive', 31.221180153541866), ('thanks', 28.393792423109392), ('problem', 27.992755656348784), ('does', 27.789964636944465), ('know', 27.636196103699088), ('use', 27.308527977186806), ('just', 26.776405833337662), ('like', 23.261250048888936)]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for id, train_data_tfidf in enumerate(tfidf_vectores): \n",
    "    x = list(zip(vect.get_feature_names(), np.ravel(train_data_tfidf[0].sum(axis=0))))\n",
    "    def SortbyTF(inputStr):\n",
    "        return inputStr[1]\n",
    "    x.sort(key=SortbyTF, reverse = True)\n",
    "    print(id)\n",
    "    print (x[:10])\n",
    "    print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, train_data_tfidf in enumerate(tfidf_vectores): \n",
    "#     print(train_data_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Jaccard profiles <a id=\"bjp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here will be my function'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Here will be my function\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier <a id=\"train\"></a> ...work in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = []\n",
    "target = []\n",
    "for data, t in tfidf_vectores:\n",
    "    final_train_data += data\n",
    "    target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(final_train_data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions <a id=\"pred\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_data,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting <a id=\"report\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(prediction == twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categories = ['sci.space',] \n",
    "categories = ['sci.space', 'comp.graphics', 'talk.politics.misc', 'rec.sport.hockey', 'comp.sys.mac.hardware'] \n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories = categories, remove = remove )\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42, categories = categories, remove = remove )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = vect.transform(twenty_train.data)\n",
    "test_data = vect.transform(twenty_test.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(use_idf = True).fit(train_data)\n",
    "train_data_tfidf = tfidf.transform(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('space', 1086), ('don', 962), ('like', 953), ('just', 896), ('know', 871), ('think', 849), ('people', 833), ('time', 771), ('new', 750), ('10', 692)]\n",
      "31002\n"
     ]
    }
   ],
   "source": [
    "x = list(zip(vect.get_feature_names(), np.ravel(train_data.sum(axis=0))))\n",
    "def SortbyTF(inputStr):\n",
    "    return inputStr[1]\n",
    "x.sort(key=SortbyTF, reverse = True)\n",
    "print (x[:10])\n",
    "print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=5, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(test_data,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 4, 3, 2, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 3 4 3 2 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print (twenty_test.target[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85935002663825255"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prediction == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
